# Indian_Sign_Language_Live_Translator
This project is a real-time camera feed translation system that converts Indian Sign Language (ISL) to English characters using computer vision and machine learning. It offers a practical application of technology to bridge the communication gap for the hearing-impaired community.

Features
Live Translation: The project provides real-time translation of Indian Sign Language (ISL) gestures into English characters.
Computer Vision: Utilizes computer vision techniques for capturing and recognizing ISL gestures.
Machine Learning: The translation model is based on machine learning algorithms trained on a diverse ISL dataset.
User-Friendly Interface: The project has a user-friendly interface that's easy to use for both developers and end-users.
Customization: You can alter the imgtocsv.py script to collect more ISL gesture samples for the dataset, although the current model is already quite accurate. 


